import json
import re
from zemberek import TurkishMorphology

# --- AYARLAR ---
INPUT_KEYWORDS_PATH = 'keywords.json'
OUTPUT_KEYWORDS_PATH = 'keywords_clean.json' # Ã‡Ä±ktÄ± dosyasÄ± bu olacak

TURKISH_STOP_WORDS = set([
    'acaba', 'ama', 'aslÄ±nda', 'az', 'bazÄ±', 'belki', 'biri', 'birkaÃ§', 'birÅŸey', 
    'biz', 'bu', 'buna', 'bunda', 'bundan', 'bunlar', 'bunu', 'bunun', 'burada', 
    'Ã§ok', 'Ã§Ã¼nkÃ¼', 'da', 'daha', 'de', 'defa', 'diye', 'eÄŸer', 'en', 'gibi', 
    'hem', 'hep', 'hepsi', 'her', 'hiÃ§', 'iÃ§in', 'ile', 'ise', 'kez', 'ki', 'kim', 
    'mÄ±', 'mu', 'mÃ¼', 'nasÄ±l', 'ne', 'neden', 'nedir', 'nerde', 'nerede', 'nereye', 
    'niÃ§in', 'niye', 'o', 'sanki', 'ÅŸey', 'siz', 'ÅŸu', 'tÃ¼m', 've', 'veya', 'ya', 
    'yani', 'vb', 'olan', 'olarak', 'kadar', 'gÃ¶re', 'ait', 'arasÄ±nda', 'gÃ¶revi',
    'fark', 'farkÄ±', 'nedenlerinden', 'nelerdir', 'anlama', 'gelir', 'yarar', 'nasÄ±l',
    'Ã¶nlenir', 'olabilir', 'olur'
])
# --- AYARLAR SONU ---

def clean_and_normalize_keywords():
    print("Anahtar kelime temizleme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
    
    try:
        morphology = TurkishMorphology.create_with_defaults()
        print("âœ… Zemberek morfoloji motoru baÅŸlatÄ±ldÄ±.")
    except Exception as e:
        print(f"âŒ HATA: Zemberek baÅŸlatÄ±lamadÄ±. Hata: {e}")
        return

    try:
        with open(INPUT_KEYWORDS_PATH, 'r', encoding='utf-8') as f:
            dirty_keywords = json.load(f)
        print(f"âœ… '{INPUT_KEYWORDS_PATH}' dosyasÄ±ndan {len(dirty_keywords)} kelime okundu.")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âŒ HATA: '{INPUT_KEYWORDS_PATH}' dosyasÄ± okunamadÄ±: {e}")
        return

    clean_keywords = set()
    for keyword in dirty_keywords:
        keyword = keyword.lower().strip()
        if len(keyword.split()) > 4 or keyword in TURKISH_STOP_WORDS: continue
        if len(keyword) < 3 and keyword not in ['ai', 'ml', 'k', 'svm', 'cnn', 'rnn', 'lstm', 'gru', 'gpt', 'gan', 'vae']: continue

        analysis = morphology.analyze(keyword)
        if analysis.analysis_results:
            root = analysis.analysis_results[0].get_stem()
            if len(root) > 2 and root not in TURKISH_STOP_WORDS:
                 clean_keywords.add(root)
        else:
            clean_keywords.add(keyword)

    sorted_clean_keywords = sorted(list(clean_keywords))
    
    try:
        with open(OUTPUT_KEYWORDS_PATH, 'w', encoding='utf-8') as f:
            json.dump(sorted_clean_keywords, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ‰ Ä°ÅŸlem TamamlandÄ±! '{OUTPUT_KEYWORDS_PATH}' dosyasÄ± {len(sorted_clean_keywords)} temiz kelime ile oluÅŸturuldu.")
    except Exception as e:
        print(f"âŒ HATA: '{OUTPUT_KEYWORDS_PATH}' dosyasÄ± yazÄ±lÄ±rken bir sorun oluÅŸtu: {e}")

if __name__ == "__main__":
    clean_and_normalize_keywords()